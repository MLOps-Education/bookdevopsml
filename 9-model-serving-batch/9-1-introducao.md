# 9.1 Introdução

O capítulo 8 foi focado em como usar o MlServer para gerar inferencia com base em chamadas de APIs e em como versionar e controlar várias verssões de modelos na mesma instância de inferência.

Neste capítulo vamos explorar a orquestração de pipeline de inferência de modelos e vamos entender como as ferramentas de processamento distribuído podem ajudar neste processo.

Ferramenta de processamento distribuído:

* [Apache Spark](./9-2-spark.md)

Ferramentas de orquestracão:

* [Apache Airflow](./9-3-airflow.md)

Por fim vamos testar a integração entre os componentes

* [Testando tudo junto](9-4-testando-tudo-junto.md)