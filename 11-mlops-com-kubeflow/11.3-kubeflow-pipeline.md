# 11.3 Kubeflow Pipeline

[Kubeflow pipeline](https://www.kubeflow.org/docs/components/pipelines/introduction/) é uma plataforma para workflows de Machine Learning baseado em containers.
Os pipelines são desenvolvidos com a linguagem Python e traduzidos em objetos dentro do Kubernetes.
Revise os [conceitos](https://www.kubeflow.org/docs/components/pipelines/concepts/) do Pipeline para melhor entendimento.

Vamos fazer um exemplo ponta a ponta agora com o Kubeflow pipelines.

## 11.3.1 Configuração do Notebook

Antes de iniciar o exemplo precisamos criar uma [configuração](https://www.kubeflow.org/docs/components/pipelines/sdk/connect-api/#multi-user-mode) para que os notebooks do Kubeflow acesses o Kubeflow pipelines:

```yaml
apiVersion: kubeflow.org/v1alpha1
kind: PodDefault
metadata:
  name: access-ml-pipeline
  namespace: "kubeflow-user-example-com"
spec:
  desc: Allow access to Kubeflow Pipelines
  selector:
    matchLabels:
      access-ml-pipeline: "true"
  volumes:
    - name: volume-kf-pipeline-token
      projected:
        sources:
          - serviceAccountToken:
              path: token
              expirationSeconds: 7200
              audience: pipelines.kubeflow.org      
  volumeMounts:
    - mountPath: /var/run/secrets/kubeflow/pipelines
      name: volume-kf-pipeline-token
      readOnly: true
  env:
    - name: KF_PIPELINES_SA_TOKEN_PATH
      value: /var/run/secrets/kubeflow/pipelines/token
```
Crie um arquivo yaml como o exemplo e crie os recursos com o **kubectl**.
Agora podemos acessar o notebook do Kubeflow e usar a configuração para acessar o Kubeflow pipeline.

Através da WebUi do Kubeflow vamos criar um Notebook Jupyter e executar o primeiro pipeline.

Vamos usar a namespace **kubeflow-user-example-com** criada na configuração do Kuubeflow e instalar as bibliotecas Python para manipular o pipeline via notebook.
Utilize a [documentação oficial](https://www.kubeflow.org/docs/components/notebooks/quickstart-guide/) para criar o notebook Jupyter.

No notebook Jupyter execute a seguinte linha para instalar a biblioteca Python do Kubeflow Pipeline e criar uma variável para utilizarmos na namespace correta:
```
namespace="kubeflow-user-example-com"
!pip install kfp==1.8.4
```

## 11.3.2 Primeiros Pipelines
Agora vamos criar o primeiro pipeline:
```python
import kfp
import kfp.dsl as dsl
from kfp import components

@comp.create_component_from_func
def echo_op():
    print("Hello world step 1")

@dsl.pipeline(
    name='my-first-pipeline',
    description='A hello world pipeline.'
)
def hello_world_pipeline():
    echo_task = echo_op()

kfp_client=kfp.Client()
run_id = kfp_client.create_run_from_pipeline_func(hello_world_pipeline,namespace=namespace, arguments={}, experiment_name="hello_word")
```
Verifique na WebUi do Kubeflow a execução do pipeline.
Repare que utilizamos o componente [create_component_from_func](https://www.kubeflow.org/docs/components/pipelines/sdk/python-function-components/), que transforma uma função python em um componente do Kubeflow pipeline que é utilizado pelo pipeline **hello_world_pipeline**.

Agora vamos criar um exemplo de steps sequenciais.
Este exemplo ele baixa um arquivo txt do cloud storage e em seguida faz o print do resultado. Para que os steps sejam sequenciais é necessário que a saída de um step seja a entrada do seguinte ou podemos declarar a dependencia com a função ***after**:

```python
def gcs_download_op(url):
    return dsl.ContainerOp(
        name='GCS - Download',
        image='google/cloud-sdk:279.0.0',
        command=['sh', '-c'],
        arguments=['gsutil cat $0 | tee $1', url, '/tmp/results.txt'],
        file_outputs={
            'data': '/tmp/results.txt',
        }
    )
def echo_op(text):
    return dsl.ContainerOp(
        name='echo',
        image='library/bash:4.4.23',
        command=['sh', '-c'],
        arguments=['echo "$0"', text]
    )

@dsl.pipeline(
    name='sequential-pipeline',
    description='A pipeline with two sequential steps.'
)
def sequential_pipeline(url='gs://ml-pipeline/sample-data/shakespeare/shakespeare1.txt'):
    """A pipeline with two sequential steps."""
    download_task = gcs_download_op(url)
    echo_task = echo_op(download_task.output)
    echo_task2 = echo_op(download_task.output).after(echo_tarsk)

kfp_client=kfp.Client()
run_id = kfp_client.create_run_from_pipeline_func(sequential_pipeline,namespace=namespace, arguments={}, experiment_name="sequential_pipeline")
```
Após a execução deste pipeline veja a execução na WebUI do Kubeflow.

Existem muitos [exemplos](https://github.com/kubeflow/pipelines/tree/sdk/release-1.8/samples) de pipeline no repositório do Kubeflow. Teste outros exemplos como o [Data passing in python components](https://github.com/kubeflow/pipelines/blob/sdk/release-1.8/samples/tutorials/Data%20passing%20in%20python%20components/Data%20passing%20in%20python%20components%20-%20Files.py).